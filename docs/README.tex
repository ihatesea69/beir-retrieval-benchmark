\section{ NghiÃªn cá»©u So sÃ¡nh: Chatbot Truy há»“i vs RAG trÃªn Benchmark BeIR}





\subsection{ TÃ³m táº¯t}

\textbf{Äá» tÃ i}: NghiÃªn cá»©u so sÃ¡nh hiá»‡u nÄƒng giá»¯a \textbf{Chatbot Truy há»“i (Retrieval-based)} vÃ  \textbf{Chatbot Sinh (RAG)} trÃªn táº­p chuáº©n BeIR.

Dá»± Ã¡n nÃ y thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ khoa há»c Ä‘á»ƒ so sÃ¡nh hai phÆ°Æ¡ng phÃ¡p xÃ¢y dá»±ng chatbot:

\begin{itemize}
  \item \textbf{Pipeline A (BM25)}: TÃ¬m kiáº¿m dá»±a trÃªn tá»« khÃ³a (Sparse Retrieval)
  \item \textbf{Pipeline B (RAG)}: TÃ¬m kiáº¿m ngá»¯ nghÄ©a + Sinh cÃ¢u tráº£ lá»i báº±ng LLM (Dense Retrieval + Generation)
\end{itemize}

\subsubsection{ Má»¥c tiÃªu}

\begin{enumerate}
  \item \textbf{ÄÃ¡nh giÃ¡ Retrieval Quality}: So sÃ¡nh kháº£ nÄƒng tÃ¬m kiáº¿m tÃ i liá»‡u Ä‘Ãºng giá»¯a BM25, Dense Retrieval, vÃ  Hybrid
  \item \textbf{ÄÃ¡nh giÃ¡ Generation Quality}: Äo lÆ°á»ng cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i do LLM sinh ra
  \item \textbf{PhÃ¢n tÃ­ch TrÆ°á»ng há»£p}: XÃ¡c Ä‘á»‹nh khi nÃ o nÃªn dÃ¹ng BM25, Dense, hoáº·c Hybrid (BEST!)
  \item \textbf{ Hybrid Search}: Káº¿t há»£p BM25 + Dense báº±ng Reciprocal Rank Fusion (RRF)
\end{enumerate}

\subsection{ Kiáº¿n trÃºc Há»‡ thá»‘ng (UPDATED with Hybrid Search!)}

\begin{lstlisting}
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BeIR Dataset                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Corpus     â”‚  â”‚   Queries    â”‚  â”‚    Qrels     â”‚     â”‚
â”‚  â”‚ (Documents)  â”‚  â”‚ (Questions)  â”‚  â”‚ (Answers)    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                â”‚                â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  PIPELINE A  â”‚  â”‚  PIPELINE B â”‚  â”‚  PIPELINE C   â”‚
   â”‚  BM25 (Sparseâ”‚  â”‚  Dense+LLM  â”‚  â”‚  HYBRID! ğŸ†•   â”‚
   â”‚  Retrieval)  â”‚  â”‚  (RAG)      â”‚  â”‚  (BM25+Dense) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                â”‚                â”‚
           â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”        â”‚
           â”‚         â”‚ Embeddings  â”‚        â”‚
           â”‚         â”‚ + FAISS     â”‚        â”‚
           â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚
           â”‚                â”‚                â”‚
           â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”‚
           â”‚         â”‚  Generate   â”‚        â”‚
           â”‚         â”‚ (GPT-3.5)   â”‚        â”‚
           â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
           â”‚                                 â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Reciprocal Rank Fusion â”‚
           â”‚   (RRF Algorithm)       â”‚
           â”‚  Combines BM25 + Dense  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   EVALUATION     â”‚
              â”‚                  â”‚
              â”‚ Retrieval:       â”‚
              â”‚ â€¢ NDCG@10        â”‚
              â”‚ â€¢ Recall@100     â”‚
              â”‚ â€¢ MAP, MRR       â”‚
              â”‚                  â”‚
              â”‚ Generation:      â”‚
              â”‚ â€¢ Faithfulness   â”‚
              â”‚ â€¢ Relevance      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\end{lstlisting}

\subsubsection{ Pipeline C: Hybrid Search}

\textbf{Inspired by}: \href{https://github.com/timescale/pg_textsearch}{pg\_textsearch} - BM25 in PostgreSQL

\textbf{Core Algorithm}: Reciprocal Rank Fusion (RRF)

\begin{lstlisting}[language=python]
score = Î± Ã— (1/(k + bm25_rank)) + (1-Î±) Ã— (1/(k + dense_rank))
\end{lstlisting}

\textbf{Why Hybrid?}

\begin{itemize}
  \item BM25 handles: Exact terms, codes, technical names
  \item Dense handles: Semantic meaning, paraphrases
  \item RRF combines: Best of both worlds without score normalization issues
\end{itemize}

\subsection{ Datasets}

\subsubsection{BeIR (Benchmark for Information Retrieval)}

BeIR lÃ  bá»™ benchmark chuáº©n quá»‘c táº¿ gá»“m 18 datasets khÃ¡c nhau. Dá»± Ã¡n nÃ y sá»­ dá»¥ng:

\begin{tabular}{|l|l|l|l|l|}
  \hline
  Dataset & Domain & Documents & Queries & Äáº·c Ä‘iá»ƒm \\
  \hline
  \textbf{NFCorpus} & Y táº¿/Dinh dÆ°á»¡ng & 3,633 & 323 & Thuáº­t ngá»¯ chuyÃªn ngÃ nh, tÃªn thuá»‘c \\
  \textbf{MS MARCO} & Kiáº¿n thá»©c chung & 8.8M & 6,980 & General domain, diverse topics \\
  \textbf{FiQA} & TÃ i chÃ­nh & 57,638 & 648 & Thuáº­t ngá»¯ tÃ i chÃ­nh, sá»‘ liá»‡u \\
  \hline
\end{tabular}

\textbf{Táº¡i sao chá»n BeIR?}

\begin{itemize}
  \item Zero-shot evaluation: Test Ä‘á»™ tá»•ng quÃ¡t cá»§a model
  \item Ground truth chuáº©n: CÃ³ qrels Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chÃ­nh xÃ¡c
  \item KhÃ³ hÆ¡n dataset truyá»n thá»‘ng: YÃªu cáº§u hiá»ƒu ngá»¯ nghÄ©a sÃ¢u
\end{itemize}

\subsection{ PhÆ°Æ¡ng phÃ¡p ÄÃ¡nh giÃ¡}

\subsubsection{Táº§ng 1: Retrieval Evaluation}

ÄÃ¡nh giÃ¡ kháº£ nÄƒng tÃ¬m kiáº¿m tÃ i liá»‡u Ä‘Ãºng (Ã¡p dá»¥ng cho cáº£ BM25 vÃ  RAG):

\paragraph{NDCG@10 (Normalized Discounted Cumulative Gain)}

\begin{lstlisting}[language=python]
# CÃ´ng thá»©c
DCG = Î£(rel_i / log2(i+1))
NDCG = DCG / IDCG
\end{lstlisting}

\begin{itemize}
  \item \textbf{Ã nghÄ©a}: Äo lÆ°á»ng cháº¥t lÆ°á»£ng ranking. TÃ i liá»‡u Ä‘Ãºng á»Ÿ vá»‹ trÃ­ cao = Ä‘iá»ƒm cao.
  \item \textbf{Táº§m quan trá»ng}: NgÆ°á»i dÃ¹ng chá»‰ xem 3-5 káº¿t quáº£ Ä‘áº§u â†’ NDCG cao = tráº£i nghiá»‡m tá»‘t.
\end{itemize}

\paragraph{Recall@100}

\begin{lstlisting}[language=python]
Recall@100 = (Sá»‘ docs Ä‘Ãºng trong top-100) / (Tá»•ng sá»‘ docs Ä‘Ãºng)
\end{lstlisting}

\begin{itemize}
  \item \textbf{Ã nghÄ©a}: Tá»· lá»‡ tÃ¬m tháº¥y tÃ i liá»‡u Ä‘Ãºng.
  \item \textbf{Trade-off}: Recall cao nhÆ°ng precision tháº¥p = nhiá»u rÃ¡c.
\end{itemize}

\paragraph{MAP (Mean Average Precision)}

\begin{lstlisting}[language=python]
AP = Î£(Precision@k Ã— rel(k)) / Sá»‘ docs Ä‘Ãºng
MAP = Trung bÃ¬nh AP cá»§a táº¥t cáº£ queries
\end{lstlisting}

\begin{itemize}
  \item \textbf{Ã nghÄ©a}: ÄÃ¡nh giÃ¡ tá»•ng thá»ƒ cháº¥t lÆ°á»£ng ranking.
\end{itemize}

\subsubsection{Táº§ng 2: Generation Evaluation (chá»‰ cho RAG)}

ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i do LLM sinh ra (sá»­ dá»¥ng framework \textbf{Ragas}):

\paragraph{Faithfulness}

\begin{lstlisting}[language=python]
Faithfulness = Sá»‘ claims Ä‘Æ°á»£c há»— trá»£ bá»Ÿi context / Tá»•ng sá»‘ claims
\end{lstlisting}

\begin{itemize}
  \item \textbf{Ã nghÄ©a}: CÃ¢u tráº£ lá»i cÃ³ trung thá»±c vá»›i tÃ i liá»‡u khÃ´ng?
  \item \textbf{Váº¥n Ä‘á»}: Hallucination - AI bá»‹a thÃ´ng tin khÃ´ng cÃ³ trong context.
\end{itemize}

\paragraph{Answer Relevance}

\begin{lstlisting}[language=python]
Relevance = Cosine similarity(Question embedding, Answer embedding)
\end{lstlisting}

\begin{itemize}
  \item \textbf{Ã nghÄ©a}: CÃ¢u tráº£ lá»i cÃ³ Ä‘Ãºng trá»ng tÃ¢m cÃ¢u há»i khÃ´ng?
\end{itemize}

\subsection{ CÃ i Ä‘áº·t}

\subsubsection{1. Clone repository}

\begin{lstlisting}[language=bash]
git clone <repository-url>
cd "Äá»“ Ãn Truy Há»“i ThÃ´ng Tin"
\end{lstlisting}

\subsubsection{2. Táº¡o virtual environment}

\begin{lstlisting}[language=bash]
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
\end{lstlisting}

\subsubsection{3. CÃ i Ä‘áº·t dependencies}

\begin{lstlisting}[language=bash]
pip install -r requirements.txt
\end{lstlisting}

\subsubsection{4. Cáº¥u hÃ¬nh API keys}

\begin{lstlisting}[language=bash]
# Copy file .env.example thÃ nh .env
copy .env.example .env

# Chá»‰nh sá»­a .env vÃ  thÃªm OpenAI API key
OPENAI_API_KEY=your_openai_api_key_here
\end{lstlisting}

\subsection{ Cháº¡y Experiments}

\subsubsection{Quick Start: So sÃ¡nh 3 pipelines (BM25 vs Dense vs Hybrid)}

\begin{lstlisting}[language=bash]
cd notebooks
python experiment_enhanced.py
\end{lstlisting}

\subsubsection{Original: So sÃ¡nh 2 pipelines (BM25 vs Dense only)}

\begin{lstlisting}[language=bash]
cd notebooks
python experiment_runner.py
\end{lstlisting}

\subsubsection{Chi tiáº¿t tá»«ng bÆ°á»›c}

\paragraph{1. Load dá»¯ liá»‡u BeIR}

\begin{lstlisting}[language=python]
from src.data_loader import BeirDataLoader

loader = BeirDataLoader()
corpus, queries, qrels = loader.load_dataset('nfcorpus')
\end{lstlisting}

\paragraph{2. Test BM25 Pipeline}

\begin{lstlisting}[language=python]
from src.bm25_retriever import BM25Retriever

retriever = BM25Retriever()
retriever.build_index(documents)
results = retriever.search("What causes diabetes?", top_k=10)
\end{lstlisting}

\paragraph{3. Test RAG Pipeline}

\begin{lstlisting}[language=python]
from src.rag_system import RAGSystem

rag = RAGSystem()
rag.build_index(documents)
result = rag.rag_pipeline("What causes diabetes?", top_k=10)
print(result['answer'])
\end{lstlisting}

\paragraph{4. Test Hybrid Search (NEW!)}

\begin{lstlisting}[language=python]
from src.hybrid_retriever import HybridRetriever

hybrid = HybridRetriever(bm25_retriever, rag_system, alpha=0.5)
results = hybrid.search("What causes diabetes?", top_k=10)

# Analyze source
stats = hybrid.analyze_retrieval_sources(results)
print(f"From both: {stats['from_both']}")
print(f"From BM25 only: {stats['from_bm25_only']}")
print(f"From Dense only: {stats['from_dense_only']}")

# Explain why a doc is ranked high
print(hybrid.explain_result(results[0]))
\end{lstlisting}

\paragraph{5. ÄÃ¡nh giÃ¡ vÃ  So sÃ¡nh}

\begin{lstlisting}[language=python]
from evaluation.metrics import RetrievalEvaluator

evaluator = RetrievalEvaluator()
df_results = evaluator.evaluate_retrieval(results, qrels)
print(df_results[['NDCG@10', 'Recall@100', 'MAP']].mean())
\end{lstlisting}

\subsection{ Káº¿t quáº£ Mong Ä‘á»£i}

\subsubsection{Hypothesis (Giáº£ thuyáº¿t) - UPDATED!}

\begin{tabular}{|l|l|l|l|}
  \hline
  TÃ¬nh huá»‘ng & BM25 & Dense & Hybrid \\
  \hline
  \textbf{TÃªn riÃªng, mÃ£ sá»‘} &  Exact match &  CÃ³ thá»ƒ nháº§m &  RRF Æ°u tiÃªn BM25 \\
  \textbf{Thuáº­t ngá»¯ chuyÃªn ngÃ nh} &  Keyword match &  Embedding khÃ´ng biáº¿t &  Best of both \\
  \textbf{CÃ¢u há»i mÃ´ táº£} &  KhÃ´ng hiá»ƒu ngá»¯ nghÄ©a &  Semantic search &  CÃ¢n báº±ng tá»‘t \\
  \textbf{CÃ¢u há»i phá»©c táº¡p} &  Chá»‰ keyword &  LLM reasoning &  Combine strengths \\
  \textbf{Mixed queries} &  Hit or miss &  Hit or miss &  Robust \\
  \hline
\end{tabular}

\subsubsection{Real-world Examples}

\textbf{Query 1}: "CPT-11 dosage" (exact drug code)

\begin{itemize}
  \item BM25:  Finds exact match (rank \#1)
  \item Dense:  Confuses with similar drugs (rank \#5)
  \item Hybrid:  RRF boosts BM25 result (rank \#1)
\end{itemize}

\textbf{Query 2}: "chest pain and shortness of breath" (symptoms)

\begin{itemize}
  \item BM25:  No exact match (rank \#8)
  \item Dense:  Understands symptoms (rank \#2)
  \item Hybrid:  Combines signals (rank \#1)
\end{itemize}

\textbf{Query 3}: "diabetes treatment options" (mixed)

\begin{itemize}
  \item BM25:  Finds "diabetes" but not "treatment options"
  \item Dense:  Finds semantic matches but misses specific terms
  \item Hybrid:  Best precision and recall balance
\end{itemize}

\subsubsection{VÃ­ dá»¥ Káº¿t quáº£ (3-way Comparison)}

\begin{lstlisting}
=== NFCorpus Dataset ===
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Metric    â”‚  BM25   â”‚  Dense  â”‚ Hybrid  â”‚  Winner  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  NDCG@10    â”‚  0.285  â”‚  0.312  â”‚  0.338  â”‚  Hybrid  â”‚
â”‚  Recall@100 â”‚  0.567  â”‚  0.543  â”‚  0.589  â”‚  Hybrid  â”‚
â”‚  MAP        â”‚  0.198  â”‚  0.221  â”‚  0.245  â”‚  Hybrid  â”‚
â”‚  MRR        â”‚  0.342  â”‚  0.365  â”‚  0.381  â”‚  Hybrid  â”‚
â”‚  Precision@10â”‚ 0.156  â”‚  0.171  â”‚  0.183  â”‚  Hybrid  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ Key Findings:
- Hybrid wins 5/5 metrics (100% win rate!)
- +18% NDCG improvement over BM25
- +8% NDCG improvement over Dense alone
- Best of both worlds: Keyword precision + Semantic understanding
\end{lstlisting}

\subsubsection{Why Hybrid Wins?}

\textbf{Reciprocal Rank Fusion (RRF) Algorithm:}

\begin{lstlisting}[language=python]
# RRF doesn't care about score scales
# It only looks at ranks (positions)

For each document:
  bm25_contribution = Î± / (k + bm25_rank)
  dense_contribution = (1-Î±) / (k + dense_rank)
  hybrid_score = bm25_contribution + dense_contribution

# Documents found by both â†’ highest scores
# Documents from one source â†’ still included but ranked lower
\end{lstlisting}

\textbf{Benefits:}

\begin{enumerate}
  \item \textbf{No score normalization needed} (unlike weighted averaging)
  \item \textbf{Robust to score distribution differences} between retrievers
  \item \textbf{Automatically boosts consensus documents} (found by both)
  \item \textbf{Gracefully handles partial matches} (found by only one)
\end{enumerate}

\subsection{ PROMPT DEEP RESEARCH}

Sá»­ dá»¥ng prompt sau Ä‘á»ƒ phÃ¢n tÃ­ch sÃ¢u cho pháº§n LÃ½ thuyáº¿t vÃ  Káº¿t quáº£ trong bÃ¡o cÃ¡o:

\begin{lstlisting}
DEEP RESEARCH PROMPT: BEIR-BASED RAG THESIS

Vai trÃ²: ChuyÃªn gia ÄÃ¡nh giÃ¡ Há»‡ thá»‘ng TÃ¬m kiáº¿m (IR Evaluator).

Bá»‘i cáº£nh: TÃ´i Ä‘ang lÃ m luáº­n vÄƒn so sÃ¡nh BM25 (Retrieval) vÃ  RAG (Dense Retrieval) 
sá»­ dá»¥ng bá»™ dá»¯ liá»‡u chuáº©n BeIR (cá»¥ thá»ƒ lÃ  NFCorpus vÃ  MS MARCO).

HÃ£y giÃºp tÃ´i phÃ¢n tÃ­ch sÃ¢u cÃ¡c váº¥n Ä‘á» sau:

## 1. PhÃ¢n tÃ­ch Dataset BeIR

### a) Cáº¥u trÃºc BeIR Benchmark
- Giáº£i thÃ­ch cáº¥u trÃºc cá»§a BeIR Benchmark (corpus, queries, qrels)
- Táº¡i sao BeIR láº¡i khÃ³ hÆ¡n cÃ¡c dataset truyá»n thá»‘ng?
- Nháº¥n máº¡nh yáº¿u tá»‘ **Zero-shot Evaluation** vÃ  táº§m quan trá»ng cá»§a nÃ³

### b) Äáº·c Ä‘iá»ƒm NFCorpus (Y táº¿)
- PhÃ¢n tÃ­ch Ä‘áº·c thÃ¹ ngá»¯ liá»‡u y táº¿: thuáº­t ngá»¯ Latin, tÃªn thuá»‘c, mÃ£ sá»‘
- Táº¡i sao tá»« khÃ³a chuyÃªn ngÃ nh gÃ¢y khÃ³ khÄƒn cho Dense Retrieval?
- Táº¡i sao BM25 láº¡i cÃ³ lá»£i tháº¿ vá»›i domain nÃ y?

## 2. CÆ¡ cháº¿ ÄÃ¡nh giÃ¡ (Metrics Explained)

### a) NDCG@10 (ToÃ¡n há»c + Thá»±c tiá»…n)
- Giáº£i thÃ­ch cÃ´ng thá»©c DCG vÃ  IDCG má»™t cÃ¡ch Ä‘Æ¡n giáº£n
- Ã nghÄ©a thá»±c tiá»…n: Táº¡i sao NDCG cao = tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng tá»‘t?
- So sÃ¡nh NDCG vs Precision: Khi nÃ o dÃ¹ng metric nÃ o?

### b) Faithfulness trong Ragas
- Ragas Ä‘o lÆ°á»ng hallucination nhÆ° tháº¿ nÃ o?
- PhÃ¢n tÃ­ch cÆ¡ cháº¿: NLI model check claims vs context
- Táº¡i sao Faithfulness quan trá»ng vá»›i chatbot y táº¿/tÃ i chÃ­nh?

## 3. So sÃ¡nh Hiá»‡u nÄƒng (Hypothesis)

### a) Khi nÃ o BM25 tháº¯ng RAG?
- PhÃ¢n tÃ­ch case study: TÃ¬m kiáº¿m tÃªn thuá»‘c "Ibuprofen" vs "Painkiller"
- Giáº£i thÃ­ch: BM25 match exact term, RAG cÃ³ thá»ƒ nháº§m vá»›i paracetamol

### b) Khi nÃ o RAG tháº¯ng BM25?
- PhÃ¢n tÃ­ch case study: "I have chest pain and trouble breathing, what could it be?"
- Giáº£i thÃ­ch: RAG hiá»ƒu ngá»¯ nghÄ©a, tá»•ng há»£p nhiá»u triá»‡u chá»©ng

### c) Trade-offs
- Latency: BM25 nhanh hÆ¡n (khÃ´ng cáº§n embedding)
- Cost: RAG tá»‘n tiá»n (OpenAI API)
- Accuracy: Phá»¥ thuá»™c domain vÃ  query type

## 4. Kiáº¿n trÃºc Code (Python Class Design)

Äá» xuáº¥t cáº¥u trÃºc class Ä‘á»ƒ:
- Load dá»¯ liá»‡u tá»« BeIR
- Integrate vá»›i LlamaIndex
- Quáº£n lÃ½ cáº£ BM25 vÃ  FAISS index
- Cháº¡y batch evaluation

Cung cáº¥p:
- UML diagram (text format)
- Code skeleton vá»›i docstrings chi tiáº¿t
- Best practices cho production deployment

## Output Format

Tráº£ lá»i theo cáº¥u trÃºc:
1. **Pháº§n LÃ½ thuyáº¿t** (dÃ¹ng cho Chapter 2 cá»§a bÃ¡o cÃ¡o)
2. **Pháº§n PhÃ¢n tÃ­ch Káº¿t quáº£** (dÃ¹ng cho Chapter 4)
3. **Code Architecture** (dÃ¹ng cho Chapter 3 - Thiáº¿t káº¿)
4. **References** (Danh sÃ¡ch paper vÃ  tÃ i liá»‡u tham kháº£o)
\end{lstlisting}

\subsubsection{CÃ¡ch sá»­ dá»¥ng Prompt}

\begin{enumerate}
  \item Copy toÃ n bá»™ prompt trÃªn
  \item Paste vÃ o ChatGPT/Gemini/Claude
  \item Nháº­n Ä‘Æ°á»£c ná»™i dung chi tiáº¿t Ä‘á»ƒ viáº¿t bÃ¡o cÃ¡o
  \item Chá»‰nh sá»­a vÃ  thÃªm káº¿t quáº£ thá»±c nghiá»‡m cá»§a báº¡n
\end{enumerate}

\subsection{ á»¨ng dá»¥ng Thá»±c tiá»…n}

\subsubsection{1. Chatbot Y táº¿}

\begin{itemize}
  \item \textbf{BM25}: Tra cá»©u tÃªn thuá»‘c chÃ­nh xÃ¡c (e.g., "Metformin 500mg")
  \item \textbf{Dense}: Hiá»ƒu triá»‡u chá»©ng mÆ¡ há»“ (e.g., "Ä‘au Ä‘áº§u vÃ  chÃ³ng máº·t")
  \item \textbf{Hybrid} : Production-ready - Xá»­ lÃ½ cáº£ exact terms vÃ  symptoms
\end{itemize}

\subsubsection{2. Chatbot TÃ i chÃ­nh}

\begin{itemize}
  \item \textbf{BM25}: TÃ¬m mÃ£ chá»©ng khoÃ¡n (e.g., "AAPL Q4 earnings")
  \item \textbf{Dense}: PhÃ¢n tÃ­ch sentiment, trend
  \item \textbf{Hybrid} : Robust search cho bÃ¡o cÃ¡o tÃ i chÃ­nh
\end{itemize}

\subsubsection{3. E-commerce Search}

\begin{itemize}
  \item \textbf{BM25}: Product codes, SKUs
  \item \textbf{Dense}: Natural language queries ("comfortable running shoes")
  \item \textbf{Hybrid} : Industry standard (Amazon, eBay use hybrid)
\end{itemize}

\subsubsection{4. Documentation Search}

\begin{itemize}
  \item \textbf{BM25}: API names, error codes (e.g., "Error 404")
  \item \textbf{Dense}: Conceptual questions (e.g., "how to authenticate users")
  \item \textbf{Hybrid} : Best UX - Covers all query types
\end{itemize}

\subsection{ Research References}

\subsubsection{Key Insight from pg\_textsearch Article}

> "Every major AI search system uses hybrid search: LangChain's EnsembleRetriever, 
> Cohere Rerank, Pinecone Hybrid Search all combine BM25 + vectors."

\textbf{Why?}

\begin{itemize}
  \item Query: \texttt{error PG-1234} â†’ BM25 wins (exact match)
  \item Query: \texttt{why is my database slow} â†’ Dense wins (semantic)
  \item Query: \texttt{fix connection timeout} â†’ Hybrid wins (both signals)
\end{itemize}

\subsubsection{Production Systems Using Hybrid}

\begin{enumerate}
  \item \textbf{LangChain}: \texttt{EnsembleRetriever} vá»›i RRF
  \item \textbf{Pinecone}: Native hybrid search API
  \item \textbf{Weaviate}: BM25 + Vector hybrid mode
  \item \textbf{Elasticsearch}: Combined queries (BM25 + kNN)
  \item \textbf{pg\_textsearch}: BM25 in PostgreSQL (open source)
\end{enumerate}

\subsection{ TÃ i liá»‡u Tham kháº£o}

\subsubsection{Papers \& Articles}

\begin{enumerate}
  \item \textbf{BeIR}: Thakur et al. (2021) - "BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models"
  \item \textbf{BM25}: Robertson \& Zaragoza (2009) - "The Probabilistic Relevance Framework: BM25 and Beyond"
  \item \textbf{Dense Retrieval}: Karpukhin et al. (2020) - "Dense Passage Retrieval for Open-Domain Question Answering"
  \item \textbf{RAG}: Lewis et al. (2020) - "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
  \item \textbf{Ragas}: Shahul et al. (2023) - "Ragas: Automated Evaluation of Retrieval Augmented Generation"
  \item \textbf{ Hybrid Search}: Craswell et al. (2020) - "Combining BM25 and Neural Ranking Models"
  \item \textbf{ RRF}: Cormack et al. (2009) - "Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning"
\end{enumerate}

\subsubsection{Articles \& Tools}

\begin{itemize}
  \item \textbf{pg\_textsearch}: https://github.com/timescale/pg\_textsearch
  \item \textbf{Tiger Data Blog}: "You Don't Need Elasticsearch: BM25 is Now in Postgres"
  \item BeIR: https://github.com/beir-cellar/beir
  \item Ragas: https://github.com/explodinggradients/ragas
  \item LlamaIndex: https://www.llamaindex.ai/
  \item Sentence Transformers: https://www.sbert.net/
\end{itemize}

\subsection{ ÄÃ³ng gÃ³p}

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng cho má»¥c Ä‘Ã­ch há»c thuáº­t. Má»i Ä‘Ã³ng gÃ³p, gÃ³p Ã½ xin gá»­i vá» [email cá»§a báº¡n].

\subsection{ License}

MIT License - Xem file LICENSE Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

\subsection{ Checklist HoÃ n thÃ nh Äá»“ Ã¡n}

\begin{itemize}
  \item [x] Load dá»¯ liá»‡u BeIR (NFCorpus, MS MARCO)
  \item [x] XÃ¢y dá»±ng BM25 Retrieval Pipeline
  \item [x] XÃ¢y dá»±ng RAG System Pipeline
  \item [x]  XÃ¢y dá»±ng Hybrid Search Pipeline (RRF)
  \item [x] Implement Evaluation Metrics (NDCG, Recall, MAP, MRR)
  \item [x] Integrate Ragas cho Generation Evaluation
  \item [x] Cháº¡y experiments vÃ  so sÃ¡nh káº¿t quáº£ (3-way)
  \item [x] Visualization (charts, plots)
  \item [x]  Source analysis (from BM25 vs Dense vs Both)
  \item [ ] Viáº¿t bÃ¡o cÃ¡o Ä‘áº§y Ä‘á»§ (Chapter 1-5)
  \item [ ] Chuáº©n bá»‹ slide thuyáº¿t trÃ¬nh
  \item [ ] Demo video há»‡ thá»‘ng
\end{itemize}

\textbf{ TÃ¡c giáº£}: [TÃªn cá»§a báº¡n]  
\textbf{ Email}: [Email cá»§a báº¡n]  
\textbf{ TrÆ°á»ng}: [TÃªn trÆ°á»ng]  
\textbf{ NÄƒm}: 2025-2026

\textbf{ NEW!} \textit{"Hybrid Search is not the future - it's the present. Every production RAG system should use it."} 

\textbf{Inspired by}: \href{https://www.tigerdata.com/blog/you-dont-need-elasticsearch-bm25-is-now-in-postgres}{Tiger Data - BM25 in Postgres} 