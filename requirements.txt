# Core Libraries for BeIR Benchmark
beir>=2.0.0

# PostgreSQL with pgvector
psycopg2-binary>=2.9.0
pgvector>=0.2.0
asyncpg>=0.29.0
sqlalchemy>=2.0.0

# NLP & Embeddings
sentence-transformers>=2.2.0
transformers>=4.30.0
torch>=2.0.0
huggingface-hub>=0.23.0  # pin to avoid [inference] extra warning

# Traditional IR
rank-bm25>=0.2.2

# Data Processing & Visualization
pandas>=2.0.0
numpy>=1.24.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Utilities
tqdm>=4.65.0
python-dotenv>=1.0.0

# Vector Store Libraries (Optional - cho comparison)
# faiss-cpu>=1.7.4  # Replaced by PostgreSQL+pgvector
chromadb>=0.4.0

# RAG & LLM with LlamaIndex (Primary Framework)
openai>=1.0.0
llama-index>=0.10.0
llama-index-core>=0.10.0
llama-index-llms-openai>=0.1.0
llama-index-embeddings-huggingface>=0.2.0
llama-index-vector-stores-postgres>=0.1.0
llama-index-retrievers-bm25>=0.1.0

# Evaluation Framework (Optional - cho Ragas)
ragas>=0.1.0
datasets>=2.14.0

# Optional: For advanced experiments
scikit-learn>=1.3.0
nltk>=3.8.0
